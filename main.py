from comet_ml import Experimentimport torchimport torch.optim as optimimport torch.nn as nnfrom torchvision import transformsfrom functools import partialfrom tqdm import tqdmimport osfrom modular_cnn import ModularCNN, make_layersfrom torchsummary import summaryfrom torchutils import *from utils import get_train_val_idxfrom resnext_util import generate_resnext_modeltorch.backends.cudnn.benchmark=Trueprint('CUDA available:', torch.cuda.is_available())print('CUDA enabled:', torch.backends.cudnn.enabled)# torch.cuda.empty_cache()disable_experiment = TrueHP1 = {"learning_rate": 0.00004               ,"n_epochs": 100               ,"batch_size": 64               ,"num_workers": 4               ,"normalized_data": True               ,"stratified": False               ,"horizontal_flip": False               ,"max_frames": 10               ,"random_seed": 999               ,"flip_prob": 0.5               ,"dataset": "5frame_steps10"               ,"classes": ['apex', 'papillary', 'mitral', '2CH', '3CH', '4CH']               ,"model_type": "3dCNN"               ,"resolution": 100               ,"adaptive_pool": (7, 5, 5)               ,"features": [16,16,"M",16,16,"M",32,32,"M"]               ,"classifier": [0.6, 500, 0.5, 250]                }for hyper_params in [HP1]:    # create model    if hyper_params['model_type'] == "3dCNN":        model = get_modular_3dCNN(hyper_params)    elif hyper_params['model_type'] == 'resnext':        model = get_resnext(hyper_params)    else:        raise NameError("Unknown model type")    # Log number of parameters    hyper_params['trainable_params'] = sum(p.numel() for p in model.parameters())    print('N_trainable_params:', hyper_params['trainable_params'])    data_transforms = transforms.Compose([        ToTensor()        ,Normalize(0.213303, 0.21379)        # ,RandomHorizontalFlip(hyper_params["flip_prob"])    ])    # ROOT_PATH = str("/home/ido/data/" + hyper_params['dataset'])    ROOT_PATH = str('/Users/idofarhi/Documents/Thesis/Data/frames/' + hyper_params['dataset'])    master_data_set = DatasetFolderWithPaths(ROOT_PATH                                    , transform = data_transforms                                    , loader = partial(pickle_loader, min_frames = hyper_params['max_frames'], shuffle_frames = False)                                    , extensions = '.pickle'                                    )    train_idx, val_idx = get_train_val_idx(master_data_set, random_state = hyper_params['random_seed'], test_size = 0.2)    train_set = torch.utils.data.Subset(master_data_set, train_idx)    val_set = torch.utils.data.Subset(master_data_set, val_idx)    train_loader = torch.utils.data.DataLoader(train_set                                         , batch_size=hyper_params['batch_size']                                         , shuffle=True                                         # ,batch_sampler =  # TODO: add stratified sampling                                         , num_workers=hyper_params['num_workers']                                         , drop_last=False                                         )    # online_mean_and_std(train_loader)    val_loader = torch.utils.data.DataLoader(val_set                                         , batch_size=hyper_params['batch_size']                                         , shuffle=True                                         # ,batch_sampler =  # TODO: add stratified sampling                                         , num_workers=hyper_params['num_workers']                                         , drop_last=False                                         )    optimizer = optim.Adam(model.parameters(), lr=hyper_params['learning_rate'])    criterion = nn.CrossEntropyLoss()    log_number_train = log_number_val = 0    experiment = Experiment(api_key="BEnSW6NdCjUCZsWIto0yhxts1" ,project_name="thesis" ,workspace="idodox", disabled=disable_experiment)    experiment.log_parameters(hyper_params)    if "color" in hyper_params['dataset']:        grayscale = False        summary(model, (3, hyper_params["max_frames"], hyper_params["resolution"], hyper_params["resolution"]))    else:        grayscale = True        summary(model, (1, hyper_params["max_frames"], hyper_params["resolution"], hyper_params["resolution"]))    for epoch in tqdm(range(hyper_params["n_epochs"])):        log_number_train = train(epoch, train_loader, optimizer, criterion, experiment, model, log_number_train, grayscale = grayscale)        log_number_val = evaluate(epoch, val_loader, optimizer, criterion, experiment, model, log_number_val, grayscale = grayscale)print("Saving model...")torch.save(model.state_dict(), os.getcwd() + "/model.pt")